{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV_MODE = False\n",
    "\n",
    "basicpath = 'T:/Kaggle_Data/Salt/'\n",
    "path_train = basicpath + 'train/'\n",
    "path_test = basicpath + 'test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths_df = pd.read_csv(basicpath+\"/depths.csv\", index_col=\"id\")\n",
    "train_df = pd.read_csv(basicpath+\"/train.csv\", index_col=\"id\", usecols=[0])\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "\n",
    "folds_df = pd.read_csv(basicpath+\"/test_folds.csv\", index_col=\"id\")\n",
    "train_df = folds_df.join(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3920, 9) (18000, 1) (22000, 1)\n"
     ]
    }
   ],
   "source": [
    "if DEV_MODE:\n",
    "    train_df = train_df.head(100)\n",
    "    test_df = test_df.head(200)\n",
    "    depths_df = depths_df[depths_df.index.isin(train_df.index) | depths_df.index.isin(test_df.index)]\n",
    "print(train_df.shape, test_df.shape, depths_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, mask = False):\n",
    "    \"\"\"\n",
    "    Load image from a given path and pad it on the sides, so that eash side is divisible by 32 (newtwork requirement)\n",
    "    \n",
    "    if pad = True:\n",
    "        returns image as numpy.array, tuple with padding in pixels as(x_min_pad, y_min_pad, x_max_pad, y_max_pad)\n",
    "    else:\n",
    "        returns image as numpy.array\n",
    "    \"\"\"\n",
    "    img = cv2.imread(str(path))\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if mask:\n",
    "        # Convert mask to 0 and 1 format\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = torch.from_numpy(img // 255)\n",
    "        return img.float()\n",
    "    else:\n",
    "        img = torch.from_numpy(img / 255.0)\n",
    "        return img\n",
    "        #return img.float().reshape((img.shape[0],img.shape[1],1)).permute([2, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadImages(df, train_data = True):\n",
    "    path = path_train if train_data else path_test\n",
    "    path_images = path + 'images/'\n",
    "    path_masks  = path + 'masks/'\n",
    "    df[\"images\"] = [np.array(load_image(path_images+\"{}.png\".format(idx))) for idx in tqdm_notebook(df.index)]\n",
    "    if train_data:\n",
    "        df[\"masks\"] = [np.array(load_image(path_masks+\"{}.png\".format(idx), mask=True)) for idx in tqdm_notebook(df.index)]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69b424f83874f899ab092c336ba0e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3920), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3710a6780d1445ca4df70eb32caaa40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3920), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "LoadImages(train_df)\n",
    "img_size_ori = train_df['images'][0].shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fold_no = 0\n",
    "\n",
    "train_images = train_df.images[train_df.test_fold != test_fold_no]\n",
    "train_masks  = train_df.masks[train_df.test_fold != test_fold_no]\n",
    "validate_images = train_df.images[train_df.test_fold == test_fold_no]\n",
    "validate_masks  = train_df.masks[train_df.test_fold == test_fold_no]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 101)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_masks[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4816714219998361, 0.11148821093364449)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_val = np.mean(train_images.apply(np.mean))\n",
    "mean_std = np.mean(train_images.apply(np.std))\n",
    "mean_val, mean_std "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3920, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_image_size = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, '../3rd_party/albumentations')\n",
    "sys.path.insert(1, '../3rd_party/imgaug')\n",
    "import albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_aug(p=1.):\n",
    "    return albumentations.Compose([\n",
    "        albumentations.HorizontalFlip(),\n",
    "        albumentations.RandomCrop(nn_image_size, nn_image_size),\n",
    "        albumentations.Normalize(mean = mean_val, std = mean_std, max_pixel_value = 1.0),\n",
    "    ], p=p)\n",
    "augmentation = basic_aug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TGSSaltDataset(data.Dataset):\n",
    "    def __init__(self, images, masks = None):\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "        self.num_inputs  =1\n",
    "        self.num_targets = 1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        assert index in range(0, self.__len__())\n",
    "        \n",
    "        image = self.images[index]\n",
    "        mask = self.masks[index] if not self.masks is None else None\n",
    "        aug_res = augmentation(image = image, mask = mask)\n",
    "        image = aug_res['image']\n",
    "        image = torch.from_numpy(image).float().permute([2, 0, 1])\n",
    "        if not self.masks is None:\n",
    "            mask = torch.from_numpy(aug_res['mask']).float().reshape((1, image.shape[1],image.shape[2]))\n",
    "            return (image, mask,)\n",
    "        else:\n",
    "            return (image,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IOU loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.array([0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95])\n",
    "\n",
    "def iou(img_true, img_pred):\n",
    "    i = np.sum(((img_true*img_pred) >0))\n",
    "    u = np.sum(((img_true + img_pred) >0))\n",
    "    if u == 0:\n",
    "        return u\n",
    "    return i/u\n",
    "\n",
    "def iou_metric(imgs_true, imgs_pred):\n",
    "    num_images = len(imgs_true)\n",
    "    scores = np.zeros(num_images)\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        if imgs_true[i].sum() == imgs_pred[i].sum() == 0:\n",
    "            scores[i] = 1.\n",
    "        else:\n",
    "            scores[i] = (thresholds <= iou(imgs_true[i], imgs_pred[i])).mean()\n",
    "            \n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    y_pred_in = (y_pred_in > 0.5).cpu().numpy() # added by sgx 20180728\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch].cpu().numpy(), y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    #print(\"metric = \",metric)\n",
    "    return np.mean(metric)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(r'../3rd_party/pytorch-summary')\n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using C:\\Users\\ovod\\AppData\\Local\\Temp\\torch_extensions as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file C:\\Users\\ovod\\AppData\\Local\\Temp\\torch_extensions\\inplace_abn\\build.ninja...\n",
      "Building extension module inplace_abn...\n",
      "Loading extension module inplace_abn...\n"
     ]
    }
   ],
   "source": [
    "sys.path.insert(1, '../3rd_party/TernausNetV2')\n",
    "from models.ternausnet2 import TernausNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_path):\n",
    "    model = TernausNetV2(num_classes=1, num_filters=32, num_input_channels=1)\n",
    "    state = torch.load('../TernausNetV2/weights/deepglobe_buildings.pt')\n",
    "    state = {key.replace('module.', '').replace('bn.', ''): value for key, value in state['model'].items()}\n",
    "\n",
    "    #model.load_state_dict(state)\n",
    "    model.train()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model('weights/deepglobe_buildings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchsummary.summary(model, (1, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace)\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (4): ReLU(inplace)\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (7): ReLU(inplace)\n",
       "  (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (9): ReLU(inplace)\n",
       "  (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (12): ReLU(inplace)\n",
       "  (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (14): ReLU(inplace)\n",
       "  (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (17): ReLU(inplace)\n",
       "  (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (19): ReLU(inplace)\n",
       "  (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import models\n",
    "model = models.vgg11().features\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 96, 96]           1,792\n",
      "              ReLU-2           [-1, 64, 96, 96]               0\n",
      "         MaxPool2d-3           [-1, 64, 48, 48]               0\n",
      "            Conv2d-4          [-1, 128, 48, 48]          73,856\n",
      "              ReLU-5          [-1, 128, 48, 48]               0\n",
      "         MaxPool2d-6          [-1, 128, 24, 24]               0\n",
      "            Conv2d-7          [-1, 256, 24, 24]         295,168\n",
      "              ReLU-8          [-1, 256, 24, 24]               0\n",
      "            Conv2d-9          [-1, 256, 24, 24]         590,080\n",
      "             ReLU-10          [-1, 256, 24, 24]               0\n",
      "        MaxPool2d-11          [-1, 256, 12, 12]               0\n",
      "           Conv2d-12          [-1, 512, 12, 12]       1,180,160\n",
      "             ReLU-13          [-1, 512, 12, 12]               0\n",
      "           Conv2d-14          [-1, 512, 12, 12]       2,359,808\n",
      "             ReLU-15          [-1, 512, 12, 12]               0\n",
      "        MaxPool2d-16            [-1, 512, 6, 6]               0\n",
      "           Conv2d-17            [-1, 512, 6, 6]       2,359,808\n",
      "             ReLU-18            [-1, 512, 6, 6]               0\n",
      "           Conv2d-19            [-1, 512, 6, 6]       2,359,808\n",
      "             ReLU-20            [-1, 512, 6, 6]               0\n",
      "        MaxPool2d-21            [-1, 512, 3, 3]               0\n",
      "================================================================\n",
      "Total params: 9,220,480\n",
      "Trainable params: 9,220,480\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 22.96\n",
      "Params size (MB): 35.17\n",
      "Estimated Total Size (MB): 58.24\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model, (3, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_0\n",
    "from imp import reload\n",
    "model_0 = reload(model_0)\n",
    "model = model_0.get_model().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 96, 96]           1,792\n",
      "            Conv2d-2           [-1, 64, 96, 96]           1,792\n",
      "              ReLU-3           [-1, 64, 96, 96]               0\n",
      "              ReLU-4           [-1, 64, 96, 96]               0\n",
      "         MaxPool2d-5           [-1, 64, 48, 48]               0\n",
      "            Conv2d-6          [-1, 128, 48, 48]          73,856\n",
      "            Conv2d-7          [-1, 128, 48, 48]          73,856\n",
      "              ReLU-8          [-1, 128, 48, 48]               0\n",
      "              ReLU-9          [-1, 128, 48, 48]               0\n",
      "        MaxPool2d-10          [-1, 128, 24, 24]               0\n",
      "           Conv2d-11          [-1, 256, 24, 24]         295,168\n",
      "           Conv2d-12          [-1, 256, 24, 24]         295,168\n",
      "             ReLU-13          [-1, 256, 24, 24]               0\n",
      "             ReLU-14          [-1, 256, 24, 24]               0\n",
      "           Conv2d-15          [-1, 256, 24, 24]         590,080\n",
      "           Conv2d-16          [-1, 256, 24, 24]         590,080\n",
      "             ReLU-17          [-1, 256, 24, 24]               0\n",
      "             ReLU-18          [-1, 256, 24, 24]               0\n",
      "        MaxPool2d-19          [-1, 256, 12, 12]               0\n",
      "           Conv2d-20          [-1, 512, 12, 12]       1,180,160\n",
      "           Conv2d-21          [-1, 512, 12, 12]       1,180,160\n",
      "             ReLU-22          [-1, 512, 12, 12]               0\n",
      "             ReLU-23          [-1, 512, 12, 12]               0\n",
      "           Conv2d-24          [-1, 512, 12, 12]       2,359,808\n",
      "           Conv2d-25          [-1, 512, 12, 12]       2,359,808\n",
      "             ReLU-26          [-1, 512, 12, 12]               0\n",
      "             ReLU-27          [-1, 512, 12, 12]               0\n",
      "        MaxPool2d-28            [-1, 512, 6, 6]               0\n",
      "           Conv2d-29            [-1, 512, 6, 6]       2,359,808\n",
      "           Conv2d-30            [-1, 512, 6, 6]       2,359,808\n",
      "             ReLU-31            [-1, 512, 6, 6]               0\n",
      "             ReLU-32            [-1, 512, 6, 6]               0\n",
      "           Conv2d-33            [-1, 512, 6, 6]       2,359,808\n",
      "           Conv2d-34            [-1, 512, 6, 6]       2,359,808\n",
      "             ReLU-35            [-1, 512, 6, 6]               0\n",
      "             ReLU-36            [-1, 512, 6, 6]               0\n",
      "        MaxPool2d-37            [-1, 512, 3, 3]               0\n",
      "           Conv2d-38            [-1, 512, 3, 3]       2,359,808\n",
      "             ReLU-39            [-1, 512, 3, 3]               0\n",
      "         ConvRelu-40            [-1, 512, 3, 3]               0\n",
      "  ConvTranspose2d-41            [-1, 256, 6, 6]       1,179,904\n",
      "             ReLU-42            [-1, 256, 6, 6]               0\n",
      "     DecoderBlock-43            [-1, 256, 6, 6]               0\n",
      "           Conv2d-44            [-1, 512, 6, 6]       3,539,456\n",
      "             ReLU-45            [-1, 512, 6, 6]               0\n",
      "         ConvRelu-46            [-1, 512, 6, 6]               0\n",
      "  ConvTranspose2d-47          [-1, 256, 12, 12]       1,179,904\n",
      "             ReLU-48          [-1, 256, 12, 12]               0\n",
      "     DecoderBlock-49          [-1, 256, 12, 12]               0\n",
      "           Conv2d-50          [-1, 512, 12, 12]       3,539,456\n",
      "             ReLU-51          [-1, 512, 12, 12]               0\n",
      "         ConvRelu-52          [-1, 512, 12, 12]               0\n",
      "  ConvTranspose2d-53          [-1, 128, 24, 24]         589,952\n",
      "             ReLU-54          [-1, 128, 24, 24]               0\n",
      "     DecoderBlock-55          [-1, 128, 24, 24]               0\n",
      "           Conv2d-56          [-1, 256, 24, 24]         884,992\n",
      "             ReLU-57          [-1, 256, 24, 24]               0\n",
      "         ConvRelu-58          [-1, 256, 24, 24]               0\n",
      "  ConvTranspose2d-59           [-1, 64, 48, 48]         147,520\n",
      "             ReLU-60           [-1, 64, 48, 48]               0\n",
      "     DecoderBlock-61           [-1, 64, 48, 48]               0\n",
      "           Conv2d-62          [-1, 128, 48, 48]         221,312\n",
      "             ReLU-63          [-1, 128, 48, 48]               0\n",
      "         ConvRelu-64          [-1, 128, 48, 48]               0\n",
      "  ConvTranspose2d-65           [-1, 32, 96, 96]          36,896\n",
      "             ReLU-66           [-1, 32, 96, 96]               0\n",
      "     DecoderBlock-67           [-1, 32, 96, 96]               0\n",
      "           Conv2d-68           [-1, 32, 96, 96]          27,680\n",
      "             ReLU-69           [-1, 32, 96, 96]               0\n",
      "         ConvRelu-70           [-1, 32, 96, 96]               0\n",
      "           Conv2d-71            [-1, 1, 96, 96]              33\n",
      "================================================================\n",
      "Total params: 32,147,873\n",
      "Trainable params: 32,147,873\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 75.80\n",
      "Params size (MB): 122.63\n",
      "Estimated Total Size (MB): 198.54\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model, (3, 96, 96))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение (torchtools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../3rd_party/torchtools')\n",
    "sys.path.append('../3rd_party/tensorboard_logger')\n",
    "sys.path.append('../3rd_party/tensorboardX')\n",
    "import torchtools.trainer\n",
    "import imp\n",
    "torchtools.trainer = imp.reload(torchtools.trainer)\n",
    "from torchtools.meters import LossMeter, AccuracyMeter\n",
    "from torchtools.callbacks import (\n",
    "    StepLR, ReduceLROnPlateau, TensorBoardLogger, CSVLogger)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3075c43fecb445d09f6eca5a4fdabc66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "101a93bd51f1494aa4570e3afc0dbaf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-0564d1553df9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m     loss, val_loss, acc, val_acc, scheduler, reduce_lr, logger, csv_logger])\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Programming\\Kaggle\\Salt\\3rd_party\\torchtools\\torchtools\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, max_epoch, checkpoint)\u001b[0m\n\u001b[0;32m    240\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotify_registered_hooks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'on_batch_start'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m                     \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                     \u001b[1;32mdef\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = TGSSaltDataset(train_images, train_masks)\n",
    "train_data_loader = data.DataLoader(dataset, batch_size = 30, shuffle = True)\n",
    "dataset_val = TGSSaltDataset(validate_images, validate_masks)\n",
    "val_data_loader = data.DataLoader(dataset_val, batch_size = 50, shuffle = False)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "trainer = torchtools.trainer.Trainer(model, train_data_loader, criterion, optimizer, val_data_loader, device='cuda')\n",
    "\n",
    "# Callbacks\n",
    "\n",
    "loss = LossMeter('loss')\n",
    "val_loss = LossMeter('val_loss')\n",
    "acc = AccuracyMeter('acc')\n",
    "val_acc = AccuracyMeter('val_acc')\n",
    "scheduler = StepLR(optimizer, 1, gamma=0.95)\n",
    "reduce_lr = ReduceLROnPlateau(optimizer, 'val_loss', factor=0.3, patience=3)\n",
    "logger = TensorBoardLogger()\n",
    "csv_logger = CSVLogger(keys=['epochs', 'loss', 'acc', 'val_loss', 'val_acc'])\n",
    "\n",
    "trainer.register_hooks([\n",
    "    loss, val_loss, acc, val_acc, scheduler, reduce_lr, logger, csv_logger])\n",
    "\n",
    "_ = trainer.train(EPOCHS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение (torchsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('../3rd_party/torchsample')\n",
    "sys.path.append('../3rd_party/nibabel')\n",
    "from torchsample.modules import ModuleTrainer\n",
    "from torchsample.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from torchsample.regularizers import L1Regularizer, L2Regularizer\n",
    "from torchsample.constraints import UnitNorm\n",
    "from torchsample.initializers import XavierUniform\n",
    "from torchsample.metrics import Metric, BinaryAccuracy\n",
    "from torchsample import TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fnmatch import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyIouMetric(Metric):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.total = 0\n",
    "        self.total_count = 0\n",
    "        self._name = 'my_iou_metric'\n",
    "\n",
    "    def reset(self):\n",
    "        self.total = 0\n",
    "        self.total_count = 0\n",
    "\n",
    "    def __call__(self, y_pred, y_true):\n",
    "        self.total += iou_metric_batch(y_true, y_pred)\n",
    "        self.total_count += 1\n",
    "        return self.total/self.total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   0%|                                                                        | 0/126 [00:00<?, ? batches/s]../3rd_party/torchsample\\torchsample\\modules\\module_trainer.py:381: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  batch_logs['loss'] = loss.data[0]\n",
      "Epoch 1/20: 100%|████████████████████████████████████| 126/126 [00:16<00:00,  7.82 batches/s, loss=0.5358, my_iou=0.07]../3rd_party/torchsample\\torchsample\\modules\\module_trainer.py:658: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(input_batch, volatile=volatile), Variable(target_batch, volatile=volatile, requires_grad=False)\n",
      "../3rd_party/torchsample\\torchsample\\modules\\module_trainer.py:551: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  eval_logs['val_loss'] = (samples_seen*eval_logs['val_loss'] + loss.data[0]*batch_size) / (samples_seen+batch_size)\n",
      "Epoch 1/20: : 127 batches [00:17,  1.62 batches/s, loss=tensor(0.3500, device='cuda:0'), val_loss=tensor(0.4713, device='cuda:0'), val_my_iou=0.15, my_iou=0.07, lr=[0.0001]]        \n",
      "Epoch 2/20: : 127 batches [00:17,  1.61 batches/s, loss=tensor(0.3657, device='cuda:0'), val_loss=tensor(0.3798, device='cuda:0'), val_my_iou=0.43, my_iou=0.34, lr=[0.0001]]        \n",
      "Epoch 3/20: : 127 batches [00:17,  1.66 batches/s, loss=tensor(0.3351, device='cuda:0'), val_loss=tensor(0.3295, device='cuda:0'), val_my_iou=0.54, my_iou=0.52, lr=[0.0001]]        \n",
      "Epoch 4/20: : 127 batches [00:17,  1.64 batches/s, loss=tensor(0.2038, device='cuda:0'), val_loss=tensor(0.2898, device='cuda:0'), val_my_iou=0.58, my_iou=0.58, lr=[0.0001]]        \n",
      "Epoch 5/20: : 127 batches [00:17,  1.63 batches/s, loss=tensor(0.1373, device='cuda:0'), val_loss=tensor(0.2676, device='cuda:0'), val_my_iou=0.58, my_iou=0.61, lr=[0.0001]]        \n",
      "Epoch 6/20: : 127 batches [00:17,  1.64 batches/s, loss=tensor(0.2169, device='cuda:0'), val_loss=tensor(0.2398, device='cuda:0'), val_my_iou=0.58, my_iou=0.62, lr=[0.0001]]        \n",
      "Epoch 7/20: : 127 batches [00:17,  1.66 batches/s, loss=tensor(0.5080, device='cuda:0'), val_loss=tensor(0.2384, device='cuda:0'), val_my_iou=0.63, my_iou=0.64, lr=[0.0001]]        \n",
      "Epoch 8/20: : 127 batches [00:17,  1.61 batches/s, loss=tensor(0.0476, device='cuda:0'), val_loss=tensor(0.2113, device='cuda:0'), val_my_iou=0.62, my_iou=0.65, lr=[0.0001]]        \n",
      "Epoch 9/20: : 127 batches [00:18,  1.61 batches/s, loss=tensor(0.1804, device='cuda:0'), val_loss=tensor(0.2469, device='cuda:0'), val_my_iou=0.55, my_iou=0.65, lr=[0.0001]]        \n",
      "Epoch 10/20: : 127 batches [00:17,  1.61 batches/s, loss=tensor(0.1345, device='cuda:0'), val_loss=tensor(0.1955, device='cuda:0'), val_my_iou=0.64, my_iou=0.67, lr=[0.0001]]        \n",
      "Epoch 11/20: : 127 batches [00:17,  1.65 batches/s, loss=tensor(0.1782, device='cuda:0'), val_loss=tensor(0.1913, device='cuda:0'), val_my_iou=0.65, my_iou=0.67, lr=[0.0001]]        \n",
      "Epoch 12/20: : 127 batches [00:18,  1.59 batches/s, loss=tensor(0.4872, device='cuda:0'), val_loss=tensor(0.1854, device='cuda:0'), val_my_iou=0.65, my_iou=0.66, lr=[0.0001]]        \n",
      "Epoch 13/20: : 127 batches [00:18,  1.65 batches/s, loss=tensor(0.7099, device='cuda:0'), val_loss=tensor(0.1926, device='cuda:0'), val_my_iou=0.66, my_iou=0.67, lr=[0.0001]]        \n",
      "Epoch 14/20: : 127 batches [00:17,  1.62 batches/s, loss=tensor(0.1456, device='cuda:0'), val_loss=tensor(0.1832, device='cuda:0'), val_my_iou=0.68, my_iou=0.68, lr=[0.0001]]        \n",
      "Epoch 15/20: : 127 batches [00:17,  1.65 batches/s, loss=tensor(0.2724, device='cuda:0'), val_loss=tensor(0.1834, device='cuda:0'), val_my_iou=0.65, my_iou=0.69, lr=[0.0001]]        \n",
      "Epoch 16/20: : 127 batches [00:18,  1.60 batches/s, loss=tensor(0.3447, device='cuda:0'), val_loss=tensor(0.1713, device='cuda:0'), val_my_iou=0.65, my_iou=0.70, lr=[0.0001]]        \n",
      "Epoch 17/20: : 127 batches [00:17,  1.63 batches/s, loss=tensor(0.1167, device='cuda:0'), val_loss=tensor(0.1841, device='cuda:0'), val_my_iou=0.66, my_iou=0.69, lr=[0.0001]]        \n",
      "Epoch 18/20: : 127 batches [00:17,  1.64 batches/s, loss=tensor(0.0761, device='cuda:0'), val_loss=tensor(0.1862, device='cuda:0'), val_my_iou=0.69, my_iou=0.70, lr=[0.0001]]        \n",
      "Epoch 19/20: : 127 batches [00:18,  1.66 batches/s, loss=tensor(0.1976, device='cuda:0'), val_loss=tensor(0.1707, device='cuda:0'), val_my_iou=0.69, my_iou=0.71, lr=[0.0001]]        \n",
      "Epoch 20/20: : 127 batches [00:17,  1.63 batches/s, loss=tensor(0.1241, device='cuda:0'), val_loss=tensor(0.1825, device='cuda:0'), val_my_iou=0.70, my_iou=0.71, lr=[0.0001]]        \n"
     ]
    }
   ],
   "source": [
    "train_loader = data.DataLoader(TGSSaltDataset(train_images, train_masks), batch_size = 25, shuffle = True)\n",
    "val_loader = data.DataLoader(TGSSaltDataset(validate_images, validate_masks), batch_size = 50, shuffle = False)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "trainer = ModuleTrainer(model)\n",
    "\n",
    "callbacks = [EarlyStopping(patience=30),\n",
    "             ReduceLROnPlateau(factor=0.5, patience=10)]\n",
    "regularizers = [L1Regularizer(scale=1e-3, module_filter='*'),\n",
    "                L2Regularizer(scale=1e-5, module_filter='*')]\n",
    "constraints = [UnitNorm(frequency=3, unit='batch', module_filter='*')]\n",
    "initializers = [XavierUniform(bias=False, module_filter='*')]\n",
    "metrics = [MyIouMetric()]\n",
    "\n",
    "trainer.compile(loss=loss_fn,\n",
    "                optimizer=optimizer,\n",
    "                regularizers=None, #regularizers,\n",
    "                constraints=None,#constraints,\n",
    "                initializers=None,#initializers,\n",
    "                metrics=metrics,#metrics, \n",
    "                callbacks=callbacks)\n",
    "\n",
    "trainer.fit_loader(train_loader, val_loader, num_epoch=20, cuda_device=0, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение (ingite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../3rd_party/ignite')\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import BinaryAccuracy, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 1  Avg accuracy: 0.75 Avg loss: 0.75\n",
      "Validation Results - Epoch: 1  Avg accuracy: 0.74 Avg loss: 0.74\n",
      "Training Results - Epoch: 2  Avg accuracy: 0.76 Avg loss: 0.76\n",
      "Validation Results - Epoch: 2  Avg accuracy: 0.76 Avg loss: 0.76\n",
      "Training Results - Epoch: 3  Avg accuracy: 0.88 Avg loss: 0.88\n",
      "Validation Results - Epoch: 3  Avg accuracy: 0.87 Avg loss: 0.87\n",
      "Training Results - Epoch: 4  Avg accuracy: 0.88 Avg loss: 0.88\n",
      "Validation Results - Epoch: 4  Avg accuracy: 0.87 Avg loss: 0.87\n",
      "Training Results - Epoch: 5  Avg accuracy: 0.91 Avg loss: 0.91\n",
      "Validation Results - Epoch: 5  Avg accuracy: 0.90 Avg loss: 0.90\n",
      "Training Results - Epoch: 6  Avg accuracy: 0.91 Avg loss: 0.91\n",
      "Validation Results - Epoch: 6  Avg accuracy: 0.90 Avg loss: 0.90\n",
      "Training Results - Epoch: 7  Avg accuracy: 0.92 Avg loss: 0.92\n",
      "Validation Results - Epoch: 7  Avg accuracy: 0.91 Avg loss: 0.91\n",
      "Training Results - Epoch: 8  Avg accuracy: 0.92 Avg loss: 0.92\n",
      "Validation Results - Epoch: 8  Avg accuracy: 0.91 Avg loss: 0.91\n",
      "Training Results - Epoch: 9  Avg accuracy: 0.93 Avg loss: 0.93\n",
      "Validation Results - Epoch: 9  Avg accuracy: 0.92 Avg loss: 0.92\n",
      "Training Results - Epoch: 10  Avg accuracy: 0.93 Avg loss: 0.93\n",
      "Validation Results - Epoch: 10  Avg accuracy: 0.92 Avg loss: 0.92\n",
      "Training Results - Epoch: 11  Avg accuracy: 0.93 Avg loss: 0.93\n",
      "Validation Results - Epoch: 11  Avg accuracy: 0.93 Avg loss: 0.93\n",
      "Training Results - Epoch: 12  Avg accuracy: 0.93 Avg loss: 0.93\n",
      "Validation Results - Epoch: 12  Avg accuracy: 0.93 Avg loss: 0.93\n",
      "Training Results - Epoch: 13  Avg accuracy: 0.94 Avg loss: 0.94\n",
      "Validation Results - Epoch: 13  Avg accuracy: 0.93 Avg loss: 0.93\n",
      "Training Results - Epoch: 14  Avg accuracy: 0.94 Avg loss: 0.94\n",
      "Validation Results - Epoch: 14  Avg accuracy: 0.93 Avg loss: 0.93\n",
      "Training Results - Epoch: 15  Avg accuracy: 0.94 Avg loss: 0.94\n",
      "Validation Results - Epoch: 15  Avg accuracy: 0.93 Avg loss: 0.93\n",
      "Training Results - Epoch: 16  Avg accuracy: 0.94 Avg loss: 0.94\n",
      "Validation Results - Epoch: 16  Avg accuracy: 0.93 Avg loss: 0.93\n",
      "Training Results - Epoch: 17  Avg accuracy: 0.94 Avg loss: 0.94\n",
      "Validation Results - Epoch: 17  Avg accuracy: 0.93 Avg loss: 0.93\n",
      "Training Results - Epoch: 18  Avg accuracy: 0.95 Avg loss: 0.95\n",
      "Validation Results - Epoch: 18  Avg accuracy: 0.94 Avg loss: 0.94\n",
      "Training Results - Epoch: 19  Avg accuracy: 0.94 Avg loss: 0.94\n",
      "Validation Results - Epoch: 19  Avg accuracy: 0.93 Avg loss: 0.93\n",
      "Training Results - Epoch: 20  Avg accuracy: 0.95 Avg loss: 0.95\n",
      "Validation Results - Epoch: 20  Avg accuracy: 0.94 Avg loss: 0.94\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ignite.engine.engine.State at 0x1dec01d6c50>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = data.DataLoader(TGSSaltDataset(train_images, train_masks), batch_size = 25, shuffle = True)\n",
    "val_loader = data.DataLoader(TGSSaltDataset(validate_images, validate_masks), batch_size = 50, shuffle = False)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, loss_fn, device = \"cuda\")\n",
    "evaluator = create_supervised_evaluator(model, device = \"cuda\",\n",
    "                                        metrics={\n",
    "                                            'accuracy': BinaryAccuracy(),\n",
    "                                            'my_loss': Loss(loss_fn)\n",
    "                                        })\n",
    "\n",
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def log_training_loss(trainer):\n",
    "    #print(\"Epoch[{}] Loss: {:.2f}\".format(trainer.state.epoch, trainer.state.output))\n",
    "    pass\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(trainer):\n",
    "    evaluator.run(train_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
    "          .format(trainer.state.epoch, metrics['accuracy'], metrics['accuracy']))\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
    "          .format(trainer.state.epoch, metrics['accuracy'], metrics['accuracy']))\n",
    "\n",
    "trainer.run(train_loader, max_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c80da341dd41e2a10b5e5fafaa6922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-042b26c566aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mtrain_iou\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtqdm_notebook\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\miniconda3\\lib\\site-packages\\tqdm\\_tqdm_notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m                 \u001b[1;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\miniconda3\\lib\\site-packages\\tqdm\\_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    955\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m                             \u001b[1;31m# Print bar update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m                             \u001b[0msp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    958\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\miniconda3\\lib\\site-packages\\tqdm\\_tqdm_notebook.py\u001b[0m in \u001b[0;36mprint_status\u001b[1;34m(s, close, bar_style, desc)\u001b[0m\n\u001b[0;32m    146\u001b[0m                         \u001b[1;31m# Update bar with current n value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m                             \u001b[0mpbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[1;31m# Print stats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\miniconda3\\lib\\site-packages\\traitlets\\traitlets.py\u001b[0m in \u001b[0;36m__set__\u001b[1;34m(self, obj, value)\u001b[0m\n\u001b[0;32m    583\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTraitError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The \"%s\" trait is read-only.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\miniconda3\\lib\\site-packages\\traitlets\\traitlets.py\u001b[0m in \u001b[0;36mset\u001b[1;34m(self, obj, value)\u001b[0m\n\u001b[0;32m    572\u001b[0m             \u001b[1;31m# we explicitly compare silent to True just in case the equality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m             \u001b[1;31m# comparison above returns something other than True/False\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m             \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_notify_trait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__set__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\miniconda3\\lib\\site-packages\\traitlets\\traitlets.py\u001b[0m in \u001b[0;36m_notify_trait\u001b[1;34m(self, name, old_value, new_value)\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[0mnew\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m             \u001b[0mowner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m             \u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'change'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m         ))\n\u001b[0;32m   1141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\miniconda3\\lib\\site-packages\\ipywidgets\\widgets\\widget.py\u001b[0m in \u001b[0;36mnotify_change\u001b[1;34m(self, change)\u001b[0m\n\u001b[0;32m    595\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_send_property\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchange\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'new'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m                 \u001b[1;31m# Send new state to front-end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWidget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotify_change\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\miniconda3\\lib\\site-packages\\ipywidgets\\widgets\\widget.py\u001b[0m in \u001b[0;36msend_state\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    480\u001b[0m             \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer_paths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_remove_buffers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'method'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'update'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'state'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'buffer_paths'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbuffer_paths\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_defaults\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\miniconda3\\lib\\site-packages\\ipywidgets\\widgets\\widget.py\u001b[0m in \u001b[0;36m_send\u001b[1;34m(self, msg, buffers)\u001b[0m\n\u001b[0;32m    723\u001b[0m         \u001b[1;34m\"\"\"Sends a message to the model in the front-end.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomm\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 725\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    726\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\miniconda3\\lib\\site-packages\\ipykernel\\comm\\comm.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data, metadata, buffers)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;34m\"\"\"Send a message to the frontend-side version of this comm\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         self._publish_msg('comm_msg',\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         )\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\miniconda3\\lib\\site-packages\\ipykernel\\comm\\comm.py\u001b[0m in \u001b[0;36m_publish_msg\u001b[1;34m(self, msg_type, data, metadata, buffers, **keys)\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mparent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mident\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopic\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m             \u001b[0mbuffers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         )\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\miniconda3\\lib\\site-packages\\jupyter_client\\session.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, stream, msg_or_type, content, parent, ident, buffers, track, header, metadata)\u001b[0m\n\u001b[0;32m    746\u001b[0m             \u001b[1;31m# use dummy tracker, which will be done immediately\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m             \u001b[0mtracker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDONE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m             \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_send\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\miniconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36msend_multipart\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;34m\"\"\"Schedule send in IO thread\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\miniconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36msend_multipart\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0mmy\u001b[0m \u001b[0mthread\u001b[0m \u001b[0misn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mrunning\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mforked\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msend\u001b[0m \u001b[0mimmediately\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \"\"\"\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_really_send\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_really_send\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\miniconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;31m# wake event thread (message content is ignored)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\miniconda3\\lib\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    389\u001b[0m                                  copy_threshold=self.copy_threshold)\n\u001b[0;32m    390\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq\\backend\\cython\\socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq\\backend\\cython\\socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq\\backend\\cython\\socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\miniconda3\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "dataset = TGSSaltDataset(train_images, train_masks)\n",
    "dataset_val = TGSSaltDataset(validate_images, validate_masks)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for e in range(100):\n",
    "    train_loss = []\n",
    "    train_iou = []\n",
    "    for image, mask in tqdm.tqdm_notebook (data.DataLoader(dataset, batch_size = 30, shuffle = True)):\n",
    "        image = image.type(torch.float).cuda()\n",
    "        y_pred = model(image)\n",
    "        loss = loss_fn(y_pred, mask.cuda())\n",
    "\n",
    "        print(type(y_pred.cpu()), type(mask.cpu()))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "        #train_iou.append\n",
    "        #(iou_metric_batch(mask.cpu(), y_pred.cpu()))\n",
    "        \n",
    "    val_loss = []\n",
    "    test_iou = []\n",
    "    for image, mask in data.DataLoader(dataset_val, batch_size = 50, shuffle = False):\n",
    "        image = image.cuda()\n",
    "        y_pred = model(image)\n",
    "        loss = loss_fn(y_pred, mask.cuda())\n",
    "        val_loss.append(loss.item())\n",
    "        #test_iou.append(iou_metric_batch(mask.cpu(), y_pred.cpu()))\n",
    "\n",
    "    with open(r'D:\\Temp\\log.txt', 'w') as f:\n",
    "        print(\"Epoch: %d, Train: %.3f, Val: %.3f\" % (e, np.mean(train_loss), np.mean(val_loss)), file = f)        \n",
    "    print(\"Epoch: %d, Train: %.3f, Val: %.3f\" % (e, np.mean(train_loss), np.mean(val_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
