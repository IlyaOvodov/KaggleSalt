{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c8fc6c3e84f282d0e6f664caf9848297b6c62a16"
   },
   "source": [
    "### U-net with simple Resnet Blocks\n",
    "#### update log\n",
    "1. Correct the errors to in function iou_metric,  use \"my_iou_metric\" to moniter the training\n",
    "2. Use image size 101 x 101, no resizing\n",
    "3. Last layer dropout reduced by half\n",
    "4. replace conv2D with 2 basic resnet blocks in each level of U-net\n",
    "5.  Use faster rle_encode (> 10 times fater than RLenc ) from (https://www.kaggle.com/lpachuong/apply-crf-unet-bn-diceloss)\n",
    "6. set  random_state= 1234 \n",
    "\n",
    "Reference kernels:\n",
    "\n",
    "https://www.kaggle.com/phoenigs/u-net-dropout-augmentation-stratification\n",
    "\n",
    "https://www.kaggle.com/tgibbons/u-net-without-resizing-images\n",
    "\n",
    "https://www.kaggle.com/lpachuong/apply-crf-unet-bn-diceloss\n",
    "\n",
    "The results seems not reproducible,  sometimes good (best around IOU0.79 ), sometimes  not as good!\n",
    "Any suggestions to improve the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img#,save_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducability setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rn\n",
    "\n",
    "kSeed = 241075\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "np.random.seed(kSeed)\n",
    "rn.seed(kSeed)\n",
    "\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "tf.set_random_seed(kSeed)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Set some parameters\n",
    "img_size_ori = 101\n",
    "img_size_target = 101\n",
    "im_width = 101\n",
    "im_height = 101\n",
    "im_chan = 1\n",
    "basicpath = '../../../../Kaggle_Data/Salt/'\n",
    "path_train = basicpath + 'train/'\n",
    "path_test = basicpath + 'test/'\n",
    "\n",
    "path_train_images = path_train + 'images/'\n",
    "path_train_masks = path_train + 'masks/'\n",
    "path_test_images = path_test + 'images/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1a64babef03b9a0dbc94387a1dad54971c3e028d"
   },
   "outputs": [],
   "source": [
    "# Loading of training/testing ids and depths\n",
    "\n",
    "train_df = pd.read_csv(basicpath+\"/train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(basicpath+\"/depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "80c3768717007fb5f087d3e01619f1a9f9a3beac"
   },
   "outputs": [],
   "source": [
    "train_df[\"images\"] = [np.array(load_img(path_train_images+\"{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9f55103f7daad6f03ec874c643077fe686c31bee"
   },
   "outputs": [],
   "source": [
    "train_df[\"masks\"] = [np.array(load_img(path_train_masks+\"{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "010066dd50ef4fdfa7dabe2c946fd7491f9556fd"
   },
   "outputs": [],
   "source": [
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n",
    "\n",
    "def cov_to_class(val):    \n",
    "    for i in range(0, 11):\n",
    "        if val * 10 <= i :\n",
    "            return i\n",
    "        \n",
    "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2ad5ac1576277fc54d768933c36efd1f9ff01acd"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15,5))\n",
    "sns.distplot(train_df.coverage, kde=False, ax=axs[0])\n",
    "sns.distplot(train_df.coverage_class, bins=10, kde=False, ax=axs[1])\n",
    "plt.suptitle(\"Salt coverage\")\n",
    "axs[0].set_xlabel(\"Coverage\")\n",
    "axs[1].set_xlabel(\"Coverage class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9f34c4263989a3d95af1e5922c1b7d2126655610"
   },
   "outputs": [],
   "source": [
    "#Plotting the depth distributionsÂ¶\n",
    "\n",
    "sns.distplot(train_df.z, label=\"Train\")\n",
    "sns.distplot(test_df.z, label=\"Test\")\n",
    "plt.legend()\n",
    "plt.title(\"Depth distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "51981795f0dd6b8ca7abe4db367f48313b63811e"
   },
   "outputs": [],
   "source": [
    "# Create train/validation split stratified by salt coverage\n",
    "\n",
    "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n",
    "    train_df.index.values,\n",
    "    np.array(train_df.images.tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "    np.array(train_df.masks.tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "    train_df.coverage.values,\n",
    "    train_df.z.values,\n",
    "    test_size=0.2, stratify=train_df.coverage_class, random_state= 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7fb577cdf27f365d4a912728c2a7654d0e60fac8"
   },
   "outputs": [],
   "source": [
    "ACTIVATION = \"relu\"\n",
    "\n",
    "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
    "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    if activation == True:\n",
    "        x = Activation(ACTIVATION)(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(blockInput, num_filters=16):\n",
    "    x = Activation(ACTIVATION)(blockInput)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = convolution_block(x, num_filters, (3,3) )\n",
    "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
    "    x = Add()([x, blockInput])\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "02967d71ee7f936254ab54acf2aa7c2e038a2b21"
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "def build_model(input_layer, start_neurons, DropoutRatio = 0.5):\n",
    "    # 101 -> 50\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n",
    "    conv1 = residual_block(conv1,start_neurons * 1)\n",
    "    conv1 = residual_block(conv1,start_neurons * 1)\n",
    "    conv1 = Activation(ACTIVATION)(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    pool1 = Dropout(DropoutRatio/2)(pool1)\n",
    "\n",
    "    # 50 -> 25\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n",
    "    conv2 = residual_block(conv2,start_neurons * 2)\n",
    "    conv2 = residual_block(conv2,start_neurons * 2)\n",
    "    conv2 = Activation(ACTIVATION)(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    pool2 = Dropout(DropoutRatio)(pool2)\n",
    "\n",
    "    # 25 -> 12\n",
    "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n",
    "    conv3 = residual_block(conv3,start_neurons * 4)\n",
    "    conv3 = residual_block(conv3,start_neurons * 4)\n",
    "    conv3 = Activation(ACTIVATION)(conv3)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    pool3 = Dropout(DropoutRatio)(pool3)\n",
    "\n",
    "    # 12 -> 6\n",
    "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n",
    "    conv4 = residual_block(conv4,start_neurons * 8)\n",
    "    conv4 = residual_block(conv4,start_neurons * 8)\n",
    "    conv4 = Activation(ACTIVATION)(conv4)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = Dropout(DropoutRatio)(pool4)\n",
    "\n",
    "    # Middle\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n",
    "    convm = residual_block(convm,start_neurons * 16)\n",
    "    convm = residual_block(convm,start_neurons * 16)\n",
    "    convm = Activation(ACTIVATION)(convm)\n",
    "    \n",
    "    # 6 -> 12\n",
    "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = Dropout(DropoutRatio)(uconv4)\n",
    "    \n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8)\n",
    "    uconv4 = Activation(ACTIVATION)(uconv4)\n",
    "    \n",
    "    # 12 -> 25\n",
    "    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"valid\")(uconv4)\n",
    "    uconv3 = concatenate([deconv3, conv3])    \n",
    "    uconv3 = Dropout(DropoutRatio)(uconv3)\n",
    "    \n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4)\n",
    "    uconv3 = Activation(ACTIVATION)(uconv3)\n",
    "\n",
    "    # 25 -> 50\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "        \n",
    "    uconv2 = Dropout(DropoutRatio)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2)\n",
    "    uconv2 = Activation(ACTIVATION)(uconv2)\n",
    "    \n",
    "    # 50 -> 101\n",
    "    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    \n",
    "    uconv1 = Dropout(DropoutRatio)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1)\n",
    "    uconv1 = Activation(ACTIVATION)(uconv1)\n",
    "    \n",
    "    uconv1 = Dropout(DropoutRatio/2)(uconv1)\n",
    "    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b9d158f567c829c55139acc9e79a41761d911726"
   },
   "outputs": [],
   "source": [
    "thresholds = np.array([0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95])\n",
    "\n",
    "def iou(img_true, img_pred):\n",
    "    i = np.sum((img_true*img_pred) >0)\n",
    "    u = np.sum((img_true + img_pred) >0)\n",
    "    if u == 0:\n",
    "        return u\n",
    "    return i/u\n",
    "\n",
    "def iou_metric(imgs_true, imgs_pred):\n",
    "    num_images = len(imgs_true)\n",
    "    scores = np.zeros(num_images)\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        if imgs_true[i].sum() == imgs_pred[i].sum() == 0:\n",
    "            scores[i] = 1\n",
    "        else:\n",
    "            scores[i] = (thresholds <= iou(imgs_true[i], imgs_pred[i])).mean()\n",
    "            \n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    y_pred_in = y_pred_in > 0.5 # added by sgx 20180728\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    #print(\"metric = \",metric)\n",
    "    return np.mean(metric)\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    metric_value = tf.py_func(iou_metric_batch, [label, pred], tf.float64)\n",
    "    return metric_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "072ab621d38cc93d26998f391357cb6efc791600"
   },
   "outputs": [],
   "source": [
    "#Data augmentation\n",
    "x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
    "y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)\n",
    "print(x_train.shape)\n",
    "print(x_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "30622932f68888e895a9b8cac91810a1bb3c5e75"
   },
   "outputs": [],
   "source": [
    "# model\n",
    "input_layer = Input((img_size_target, img_size_target, 1))\n",
    "output_layer = build_model(input_layer, 16,0.5)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\", my_iou_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "41699081be465c14e193ffad4fd00bd56840f156",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 800 samples\n",
      "Epoch 1/200\n",
      " - 80s - loss: 0.3680 - acc: 0.8558 - my_iou_metric: 0.5409 - val_loss: 0.5601 - val_acc: 0.7955 - val_my_iou_metric: 0.4929\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.49286, saving model to ./unet_best1.model\n",
      "Epoch 2/200\n",
      " - 58s - loss: 0.2772 - acc: 0.8952 - my_iou_metric: 0.6903 - val_loss: 0.4305 - val_acc: 0.8442 - val_my_iou_metric: 0.5618\n",
      "\n",
      "Epoch 00002: val_my_iou_metric improved from 0.49286 to 0.56177, saving model to ./unet_best1.model\n",
      "Epoch 3/200\n",
      " - 58s - loss: 0.2538 - acc: 0.9048 - my_iou_metric: 0.7273 - val_loss: 0.2477 - val_acc: 0.9103 - val_my_iou_metric: 0.7513\n",
      "\n",
      "Epoch 00003: val_my_iou_metric improved from 0.56177 to 0.75129, saving model to ./unet_best1.model\n",
      "Epoch 4/200\n",
      " - 58s - loss: 0.2289 - acc: 0.9139 - my_iou_metric: 0.7506 - val_loss: 0.3413 - val_acc: 0.8488 - val_my_iou_metric: 0.6685\n",
      "\n",
      "Epoch 00004: val_my_iou_metric did not improve\n",
      "Epoch 5/200\n",
      " - 58s - loss: 0.2170 - acc: 0.9194 - my_iou_metric: 0.7647 - val_loss: 0.2246 - val_acc: 0.9132 - val_my_iou_metric: 0.7417\n",
      "\n",
      "Epoch 00005: val_my_iou_metric did not improve\n",
      "Epoch 6/200\n",
      " - 58s - loss: 0.2059 - acc: 0.9224 - my_iou_metric: 0.7760 - val_loss: 0.3059 - val_acc: 0.8877 - val_my_iou_metric: 0.6808\n",
      "\n",
      "Epoch 00006: val_my_iou_metric did not improve\n",
      "Epoch 7/200\n",
      " - 58s - loss: 0.2017 - acc: 0.9261 - my_iou_metric: 0.7829 - val_loss: 0.2289 - val_acc: 0.9252 - val_my_iou_metric: 0.7593\n",
      "\n",
      "Epoch 00007: val_my_iou_metric improved from 0.75129 to 0.75925, saving model to ./unet_best1.model\n",
      "Epoch 8/200\n",
      " - 57s - loss: 0.1832 - acc: 0.9322 - my_iou_metric: 0.7987 - val_loss: 0.2692 - val_acc: 0.9080 - val_my_iou_metric: 0.7447\n",
      "\n",
      "Epoch 00008: val_my_iou_metric did not improve\n",
      "Epoch 9/200\n",
      " - 58s - loss: 0.1916 - acc: 0.9280 - my_iou_metric: 0.7921 - val_loss: 0.1920 - val_acc: 0.9316 - val_my_iou_metric: 0.7871\n",
      "\n",
      "Epoch 00009: val_my_iou_metric improved from 0.75925 to 0.78710, saving model to ./unet_best1.model\n",
      "Epoch 10/200\n",
      " - 57s - loss: 0.1732 - acc: 0.9343 - my_iou_metric: 0.8093 - val_loss: 0.1684 - val_acc: 0.9401 - val_my_iou_metric: 0.8302\n",
      "\n",
      "Epoch 00010: val_my_iou_metric improved from 0.78710 to 0.83019, saving model to ./unet_best1.model\n",
      "Epoch 11/200\n",
      " - 57s - loss: 0.1691 - acc: 0.9365 - my_iou_metric: 0.8100 - val_loss: 0.1732 - val_acc: 0.9338 - val_my_iou_metric: 0.8226\n",
      "\n",
      "Epoch 00011: val_my_iou_metric did not improve\n",
      "Epoch 12/200\n",
      " - 58s - loss: 0.1639 - acc: 0.9392 - my_iou_metric: 0.8211 - val_loss: 0.1902 - val_acc: 0.9310 - val_my_iou_metric: 0.7950\n",
      "\n",
      "Epoch 00012: val_my_iou_metric did not improve\n",
      "Epoch 13/200\n",
      " - 58s - loss: 0.1664 - acc: 0.9386 - my_iou_metric: 0.8215 - val_loss: 0.2704 - val_acc: 0.9229 - val_my_iou_metric: 0.7923\n",
      "\n",
      "Epoch 00013: val_my_iou_metric did not improve\n",
      "Epoch 14/200\n",
      " - 60s - loss: 0.1643 - acc: 0.9389 - my_iou_metric: 0.8217 - val_loss: 0.1669 - val_acc: 0.9363 - val_my_iou_metric: 0.8209\n",
      "\n",
      "Epoch 00014: val_my_iou_metric did not improve\n",
      "Epoch 15/200\n",
      " - 60s - loss: 0.1542 - acc: 0.9416 - my_iou_metric: 0.8284 - val_loss: 0.1766 - val_acc: 0.9406 - val_my_iou_metric: 0.8266\n",
      "\n",
      "Epoch 00015: val_my_iou_metric did not improve\n",
      "Epoch 16/200\n",
      " - 64s - loss: 0.1490 - acc: 0.9443 - my_iou_metric: 0.8344 - val_loss: 0.1609 - val_acc: 0.9417 - val_my_iou_metric: 0.8314\n",
      "\n",
      "Epoch 00016: val_my_iou_metric improved from 0.83019 to 0.83136, saving model to ./unet_best1.model\n",
      "Epoch 17/200\n",
      " - 65s - loss: 0.1471 - acc: 0.9445 - my_iou_metric: 0.8364 - val_loss: 0.1570 - val_acc: 0.9409 - val_my_iou_metric: 0.8324\n",
      "\n",
      "Epoch 00017: val_my_iou_metric improved from 0.83136 to 0.83235, saving model to ./unet_best1.model\n",
      "Epoch 18/200\n",
      " - 65s - loss: 0.1581 - acc: 0.9396 - my_iou_metric: 0.8245 - val_loss: 0.1566 - val_acc: 0.9433 - val_my_iou_metric: 0.8396\n",
      "\n",
      "Epoch 00018: val_my_iou_metric improved from 0.83235 to 0.83962, saving model to ./unet_best1.model\n",
      "Epoch 19/200\n",
      " - 65s - loss: 0.1490 - acc: 0.9424 - my_iou_metric: 0.8342 - val_loss: 0.1563 - val_acc: 0.9405 - val_my_iou_metric: 0.8188\n",
      "\n",
      "Epoch 00019: val_my_iou_metric did not improve\n",
      "Epoch 20/200\n",
      " - 66s - loss: 0.1420 - acc: 0.9461 - my_iou_metric: 0.8407 - val_loss: 0.1870 - val_acc: 0.9294 - val_my_iou_metric: 0.8051\n",
      "\n",
      "Epoch 00020: val_my_iou_metric did not improve\n",
      "Epoch 21/200\n",
      " - 66s - loss: 0.1456 - acc: 0.9445 - my_iou_metric: 0.8350 - val_loss: 0.1639 - val_acc: 0.9400 - val_my_iou_metric: 0.8323\n",
      "\n",
      "Epoch 00021: val_my_iou_metric did not improve\n",
      "Epoch 22/200\n",
      " - 66s - loss: 0.1442 - acc: 0.9452 - my_iou_metric: 0.8393 - val_loss: 0.1711 - val_acc: 0.9323 - val_my_iou_metric: 0.8284\n",
      "\n",
      "Epoch 00022: val_my_iou_metric did not improve\n",
      "Epoch 23/200\n",
      " - 65s - loss: 0.1394 - acc: 0.9469 - my_iou_metric: 0.8434 - val_loss: 0.1609 - val_acc: 0.9372 - val_my_iou_metric: 0.8221\n",
      "\n",
      "Epoch 00023: val_my_iou_metric did not improve\n",
      "Epoch 24/200\n",
      " - 65s - loss: 0.1378 - acc: 0.9472 - my_iou_metric: 0.8438 - val_loss: 0.1500 - val_acc: 0.9441 - val_my_iou_metric: 0.8384\n",
      "\n",
      "Epoch 00024: val_my_iou_metric did not improve\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 25/200\n",
      " - 65s - loss: 0.1200 - acc: 0.9529 - my_iou_metric: 0.8581 - val_loss: 0.1664 - val_acc: 0.9362 - val_my_iou_metric: 0.8278\n",
      "\n",
      "Epoch 00025: val_my_iou_metric did not improve\n",
      "Epoch 26/200\n",
      " - 65s - loss: 0.1134 - acc: 0.9558 - my_iou_metric: 0.8615 - val_loss: 0.1415 - val_acc: 0.9469 - val_my_iou_metric: 0.8494\n",
      "\n",
      "Epoch 00026: val_my_iou_metric improved from 0.83962 to 0.84937, saving model to ./unet_best1.model\n",
      "Epoch 27/200\n",
      " - 65s - loss: 0.1123 - acc: 0.9557 - my_iou_metric: 0.8613 - val_loss: 0.1469 - val_acc: 0.9434 - val_my_iou_metric: 0.8372\n",
      "\n",
      "Epoch 00027: val_my_iou_metric did not improve\n",
      "Epoch 28/200\n",
      " - 65s - loss: 0.1153 - acc: 0.9547 - my_iou_metric: 0.8613 - val_loss: 0.1386 - val_acc: 0.9466 - val_my_iou_metric: 0.8465\n",
      "\n",
      "Epoch 00028: val_my_iou_metric did not improve\n",
      "Epoch 29/200\n",
      " - 66s - loss: 0.1105 - acc: 0.9565 - my_iou_metric: 0.8629 - val_loss: 0.1490 - val_acc: 0.9451 - val_my_iou_metric: 0.8416\n",
      "\n",
      "Epoch 00029: val_my_iou_metric did not improve\n",
      "Epoch 30/200\n",
      " - 65s - loss: 0.1102 - acc: 0.9569 - my_iou_metric: 0.8636 - val_loss: 0.1421 - val_acc: 0.9455 - val_my_iou_metric: 0.8450\n",
      "\n",
      "Epoch 00030: val_my_iou_metric did not improve\n",
      "Epoch 31/200\n",
      " - 65s - loss: 0.1088 - acc: 0.9567 - my_iou_metric: 0.8643 - val_loss: 0.1524 - val_acc: 0.9421 - val_my_iou_metric: 0.8416\n",
      "\n",
      "Epoch 00031: val_my_iou_metric did not improve\n",
      "Epoch 32/200\n",
      " - 66s - loss: 0.1085 - acc: 0.9578 - my_iou_metric: 0.8639 - val_loss: 0.1610 - val_acc: 0.9430 - val_my_iou_metric: 0.8438\n",
      "\n",
      "Epoch 00032: val_my_iou_metric did not improve\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 33/200\n",
      " - 65s - loss: 0.1040 - acc: 0.9588 - my_iou_metric: 0.8678 - val_loss: 0.1500 - val_acc: 0.9444 - val_my_iou_metric: 0.8468\n",
      "\n",
      "Epoch 00033: val_my_iou_metric did not improve\n",
      "Epoch 34/200\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_my_iou_metric', mode = 'max',patience=10, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(\"./unet_best1.model\",monitor='val_my_iou_metric', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric', mode = 'max',factor=0.2, patience=5, min_lr=0.00001, verbose=1)\n",
    "#reduce_lr = ReduceLROnPlateau(factor=0.2, patience=5, min_lr=0.00001, verbose=1)\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 25\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=[x_valid, y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[early_stopping, model_checkpoint, reduce_lr], \n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "81aba20e2904bcab1c3ac601f28a880f856e491b"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['acc'][1:])\n",
    "plt.plot(history.history['val_acc'][1:])\n",
    "plt.plot(history.history['my_iou_metric'][1:])\n",
    "plt.plot(history.history['val_my_iou_metric'][1:])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "347c6567c95430f28ec51b94f42603e37a4056db"
   },
   "outputs": [],
   "source": [
    "fig, (ax_loss, ax_acc) = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax_loss.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "ax_loss.plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a081f8f61a713457c8c8f3979a78f75541875456"
   },
   "outputs": [],
   "source": [
    "model = load_model(\"./unet_best1.model\",custom_objects={'my_iou_metric': my_iou_metric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5da2648534e6f8a4d2fbd8995cf9e6a1c9c0d227"
   },
   "outputs": [],
   "source": [
    "def predict_result(model,x_test,img_size_target): # predict both orginal and reflect x\n",
    "    preds_test = model.predict(x_test).reshape(-1, img_size_target, img_size_target)\n",
    "    preds_test += np.array([ np.fliplr(a) for a in model.predict(np.array([np.fliplr(x) for x in x_test])).reshape(-1, img_size_target, img_size_target)])\n",
    "    return preds_test/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b7a061700364ea17735f953d6bd3c835bc3dc630"
   },
   "outputs": [],
   "source": [
    "preds_valid = predict_result(model,x_valid,img_size_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "91b1be75d7e8ff74db956c8c846c47ed7576ecb2"
   },
   "outputs": [],
   "source": [
    "def filter_image(img):\n",
    "    if img.sum() < 100:\n",
    "        return np.zeros(img.shape)\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "## Scoring for last model\n",
    "thresholds = np.linspace(0.3, 0.7, 31)\n",
    "ious = np.array([iou_metric(y_valid.reshape((-1, img_size_target, img_size_target)), [filter_image(img) for img in preds_valid > threshold]) for threshold in tqdm_notebook(thresholds)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1beb285910aa6532d7a69a70afa6a9671e6d347d"
   },
   "outputs": [],
   "source": [
    "threshold_best_index = np.argmax(ious) \n",
    "iou_best = ious[threshold_best_index]\n",
    "threshold_best = thresholds[threshold_best_index]\n",
    "\n",
    "plt.plot(thresholds, ious)\n",
    "plt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2c4852ecf2c504a4ce30e975f5e36b534c2111e6"
   },
   "outputs": [],
   "source": [
    "def rle_encode(im):\n",
    "    pixels = im.flatten(order = 'F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e84d3cc4fd7b6b7517a5eab0c0b9df38421e0c13"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del x_train, x_valid, y_train, y_valid, preds_valid\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "21bb50645b1c67d907e42c262d92f975668fccac"
   },
   "outputs": [],
   "source": [
    "x_test = np.array([(np.array(load_img(path_test_images+\"{}.png\".format(idx), grayscale = True))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)\n",
    "\n",
    "preds_test = predict_result(model,x_test,img_size_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7ccac81a492b9caaff4a25401165e145cf2c6f8e"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "pred_dict = {idx: rle_encode(filter_image(preds_test[i] > threshold_best)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}\n",
    "t2 = time.time()\n",
    "\n",
    "print(f\"Usedtime = {t2-t1} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "770d7d596656f4f1ad17a6063ad662ac80e11b24"
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv('submission.csv.gz', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "031bc2ef4548059939fae54c06f24f68e0ad3330"
   },
   "outputs": [],
   "source": [
    "sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
