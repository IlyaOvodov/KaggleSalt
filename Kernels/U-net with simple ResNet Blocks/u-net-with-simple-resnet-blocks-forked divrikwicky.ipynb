{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c8fc6c3e84f282d0e6f664caf9848297b6c62a16"
   },
   "source": [
    "### U-net with simple Resnet Blocks\n",
    "#### update log\n",
    "1. Correct the errors to in function iou_metric,  use \"my_iou_metric\" to moniter the training\n",
    "2. Use image size 101 x 101, no resizing\n",
    "3. Last layer dropout reduced by half\n",
    "4. replace conv2D with 2 basic resnet blocks in each level of U-net\n",
    "5.  Use faster rle_encode (> 10 times fater than RLenc ) from (https://www.kaggle.com/lpachuong/apply-crf-unet-bn-diceloss)\n",
    "6. set  random_state= 1234 \n",
    "\n",
    "Reference kernels:\n",
    "\n",
    "https://www.kaggle.com/phoenigs/u-net-dropout-augmentation-stratification\n",
    "\n",
    "https://www.kaggle.com/tgibbons/u-net-without-resizing-images\n",
    "\n",
    "https://www.kaggle.com/lpachuong/apply-crf-unet-bn-diceloss\n",
    "\n",
    "The results seems not reproducible,  sometimes good (best around IOU0.79 ), sometimes  not as good!\n",
    "Any suggestions to improve the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img#,save_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../3rd_party/LovaszSoftmax/tensorflow')\n",
    "import lovasz_losses_tf as L_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducability setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rn\n",
    "\n",
    "kSeed = 241075\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "np.random.seed(kSeed)\n",
    "rn.seed(kSeed)\n",
    "\n",
    "#session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "tf.set_random_seed(kSeed)\n",
    "#sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "sess = tf.Session(graph=tf.get_default_graph())\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Set some parameters\n",
    "img_size_ori = 101\n",
    "img_size_target = 101\n",
    "im_width = 101\n",
    "im_height = 101\n",
    "im_chan = 1\n",
    "basicpath = 'T:/Kaggle_Data/Salt/'\n",
    "path_train = basicpath + 'train/'\n",
    "path_test = basicpath + 'test/'\n",
    "\n",
    "path_train_images = path_train + 'images/'\n",
    "path_train_masks = path_train + 'masks/'\n",
    "path_test_images = path_test + 'images/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1a64babef03b9a0dbc94387a1dad54971c3e028d"
   },
   "outputs": [],
   "source": [
    "# Loading of training/testing ids and depths\n",
    "\n",
    "train_df = pd.read_csv(basicpath+\"/train.csv\", index_col=\"id\", usecols=[0])\n",
    "depths_df = pd.read_csv(basicpath+\"/depths.csv\", index_col=\"id\")\n",
    "train_df = train_df.join(depths_df)\n",
    "test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
    "\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "80c3768717007fb5f087d3e01619f1a9f9a3beac"
   },
   "outputs": [],
   "source": [
    "train_df[\"images\"] = [np.array(load_img(path_train_images+\"{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9f55103f7daad6f03ec874c643077fe686c31bee"
   },
   "outputs": [],
   "source": [
    "train_df[\"masks\"] = [np.array(load_img(path_train_masks+\"{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "010066dd50ef4fdfa7dabe2c946fd7491f9556fd"
   },
   "outputs": [],
   "source": [
    "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n",
    "\n",
    "def cov_to_class(val):    \n",
    "    for i in range(0, 11):\n",
    "        if val * 10 <= i :\n",
    "            return i\n",
    "        \n",
    "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2ad5ac1576277fc54d768933c36efd1f9ff01acd"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15,5))\n",
    "sns.distplot(train_df.coverage, kde=False, ax=axs[0])\n",
    "sns.distplot(train_df.coverage_class, bins=10, kde=False, ax=axs[1])\n",
    "plt.suptitle(\"Salt coverage\")\n",
    "axs[0].set_xlabel(\"Coverage\")\n",
    "axs[1].set_xlabel(\"Coverage class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9f34c4263989a3d95af1e5922c1b7d2126655610"
   },
   "outputs": [],
   "source": [
    "#Plotting the depth distributionsÂ¶\n",
    "\n",
    "sns.distplot(train_df.z, label=\"Train\")\n",
    "sns.distplot(test_df.z, label=\"Test\")\n",
    "plt.legend()\n",
    "plt.title(\"Depth distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "51981795f0dd6b8ca7abe4db367f48313b63811e"
   },
   "outputs": [],
   "source": [
    "# Create train/validation split stratified by salt coverage\n",
    "\n",
    "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n",
    "    train_df.index.values,\n",
    "    np.array(train_df.images.tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "    np.array(train_df.masks.tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
    "    train_df.coverage.values,\n",
    "    train_df.z.values,\n",
    "    test_size=0.2, stratify=train_df.coverage_class, random_state= 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7fb577cdf27f365d4a912728c2a7654d0e60fac8"
   },
   "outputs": [],
   "source": [
    "ACTIVATION = \"relu\"\n",
    "\n",
    "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
    "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    if activation == True:\n",
    "        x = Activation(ACTIVATION)(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(blockInput, num_filters=16):\n",
    "    x = Activation(ACTIVATION)(blockInput)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = convolution_block(x, num_filters, (3,3) )\n",
    "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
    "    x = Add()([x, blockInput])\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "02967d71ee7f936254ab54acf2aa7c2e038a2b21"
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "def build_model(input_layer, start_neurons, DropoutRatio = 0.5):\n",
    "    # 101 -> 50\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n",
    "    conv1 = residual_block(conv1,start_neurons * 1)\n",
    "    conv1 = residual_block(conv1,start_neurons * 1)\n",
    "    conv1 = Activation(ACTIVATION)(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    pool1 = Dropout(DropoutRatio/2)(pool1)\n",
    "\n",
    "    # 50 -> 25\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n",
    "    conv2 = residual_block(conv2,start_neurons * 2)\n",
    "    conv2 = residual_block(conv2,start_neurons * 2)\n",
    "    conv2 = Activation(ACTIVATION)(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    pool2 = Dropout(DropoutRatio)(pool2)\n",
    "\n",
    "    # 25 -> 12\n",
    "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n",
    "    conv3 = residual_block(conv3,start_neurons * 4)\n",
    "    conv3 = residual_block(conv3,start_neurons * 4)\n",
    "    conv3 = Activation(ACTIVATION)(conv3)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    pool3 = Dropout(DropoutRatio)(pool3)\n",
    "\n",
    "    # 12 -> 6\n",
    "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n",
    "    conv4 = residual_block(conv4,start_neurons * 8)\n",
    "    conv4 = residual_block(conv4,start_neurons * 8)\n",
    "    conv4 = Activation(ACTIVATION)(conv4)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = Dropout(DropoutRatio)(pool4)\n",
    "\n",
    "    # Middle\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n",
    "    convm = residual_block(convm,start_neurons * 16)\n",
    "    convm = residual_block(convm,start_neurons * 16)\n",
    "    convm = Activation(ACTIVATION)(convm)\n",
    "    \n",
    "    # 6 -> 12\n",
    "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = Dropout(DropoutRatio)(uconv4)\n",
    "    \n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8)\n",
    "    uconv4 = Activation(ACTIVATION)(uconv4)\n",
    "    \n",
    "    # 12 -> 25\n",
    "    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"valid\")(uconv4)\n",
    "    uconv3 = concatenate([deconv3, conv3])    \n",
    "    uconv3 = Dropout(DropoutRatio)(uconv3)\n",
    "    \n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4)\n",
    "    uconv3 = Activation(ACTIVATION)(uconv3)\n",
    "\n",
    "    # 25 -> 50\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "        \n",
    "    uconv2 = Dropout(DropoutRatio)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2)\n",
    "    uconv2 = Activation(ACTIVATION)(uconv2)\n",
    "    \n",
    "    # 50 -> 101\n",
    "    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    \n",
    "    uconv1 = Dropout(DropoutRatio)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1)\n",
    "    uconv1 = Activation(ACTIVATION)(uconv1)\n",
    "    \n",
    "    uconv1 = Dropout(DropoutRatio/2)(uconv1)\n",
    "    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b9d158f567c829c55139acc9e79a41761d911726"
   },
   "outputs": [],
   "source": [
    "thresholds = np.array([0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95])\n",
    "\n",
    "def iou(img_true, img_pred):\n",
    "    assert (img_true.shape[-1]==1) and (len(img_true.shape)==3) or (img_true.shape[-1]!=1) and (len(img_true.shape)==2)\n",
    "    i = np.sum((img_true*img_pred) >0)\n",
    "    u = np.sum((img_true + img_pred) >0)\n",
    "    if u == 0:\n",
    "        return u\n",
    "    return i/u\n",
    "\n",
    "def iou_metric(img_true, img_pred):\n",
    "    img_pred = img_pred > 0.5 # added by sgx 20180728\n",
    "    if img_true.sum() == img_pred.sum() == 0:\n",
    "        scores = 1\n",
    "    else:\n",
    "        scores = (thresholds <= iou(img_true, img_pred)).mean()\n",
    "    return scores\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = len(y_true_in)\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    #print(\"metric = \",metric)\n",
    "    return np.mean(metric)\n",
    "\n",
    "# adapter for Keras\n",
    "def my_iou_metric(label, pred):\n",
    "    metric_value = tf.py_func(iou_metric_batch, [label, pred], tf.float64)\n",
    "    return metric_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "072ab621d38cc93d26998f391357cb6efc791600"
   },
   "outputs": [],
   "source": [
    "#Data augmentation\n",
    "x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
    "y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)\n",
    "print(x_train.shape)\n",
    "print(x_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lavazs_loss(labels, scores): # Keras and TF has reversed order of args\n",
    "    return L_loss.lovasz_hinge(2*scores-1, labels, ignore=255, per_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "30622932f68888e895a9b8cac91810a1bb3c5e75"
   },
   "outputs": [],
   "source": [
    "# model\n",
    "input_layer = Input((img_size_target, img_size_target, 1))\n",
    "output_layer = build_model(input_layer, 16,0.5)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\", my_iou_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('./unet_best  18.09.04.23.20.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "41699081be465c14e193ffad4fd00bd56840f156",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_my_iou_metric', mode = 'max',patience=30, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(\"./unet_best1.model\",monitor='val_my_iou_metric', \n",
    "                                   mode = 'max', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric', mode = 'max',factor=0.2, patience=10, min_lr=0.00001, verbose=1)\n",
    "#reduce_lr = ReduceLROnPlateau(factor=0.2, patience=5, min_lr=0.00001, verbose=1)\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 25\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=[x_valid, y_valid], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[early_stopping, model_checkpoint, reduce_lr], \n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "81aba20e2904bcab1c3ac601f28a880f856e491b"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['acc'][1:])\n",
    "plt.plot(history.history['val_acc'][1:])\n",
    "plt.plot(history.history['my_iou_metric'][1:])\n",
    "plt.plot(history.history['val_my_iou_metric'][1:])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "347c6567c95430f28ec51b94f42603e37a4056db",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, (ax_loss, ax_acc) = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax_loss.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "ax_loss.plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a081f8f61a713457c8c8f3979a78f75541875456"
   },
   "outputs": [],
   "source": [
    "model = load_model(\"./unet_best  18.09.05.19.44x.model\",custom_objects={'my_iou_metric': my_iou_metric, 'lavazs_loss': lavazs_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5da2648534e6f8a4d2fbd8995cf9e6a1c9c0d227"
   },
   "outputs": [],
   "source": [
    "def predict_result(model,x_test,img_size_target): # predict both orginal and reflect x\n",
    "    preds_test = model.predict(x_test).reshape(-1, img_size_target, img_size_target)\n",
    "    preds_test += np.array([ np.fliplr(a) for a in model.predict(np.array([np.fliplr(x) for x in x_test])).reshape(-1, img_size_target, img_size_target)])\n",
    "    return preds_test/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b7a061700364ea17735f953d6bd3c835bc3dc630"
   },
   "outputs": [],
   "source": [
    "preds_valid = predict_result(model,x_valid,img_size_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "91b1be75d7e8ff74db956c8c846c47ed7576ecb2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filter_image(img):\n",
    "    if img.sum() < 100:\n",
    "        return np.zeros(img.shape)\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "## Scoring for last model\n",
    "thresholds = np.linspace(0.3, 0.7, 31)\n",
    "ious = np.array([iou_metric_batch(y_valid.reshape((-1, img_size_target, img_size_target)), [filter_image(img) for img in preds_valid > threshold]) for threshold in tqdm_notebook(thresholds)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1beb285910aa6532d7a69a70afa6a9671e6d347d"
   },
   "outputs": [],
   "source": [
    "threshold_best_index = np.argmax(ious) \n",
    "iou_best = ious[threshold_best_index]\n",
    "threshold_best = thresholds[threshold_best_index]\n",
    "\n",
    "plt.plot(thresholds, ious)\n",
    "plt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2c4852ecf2c504a4ce30e975f5e36b534c2111e6"
   },
   "outputs": [],
   "source": [
    "def rle_encode(im):\n",
    "    pixels = im.flatten(order = 'F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e84d3cc4fd7b6b7517a5eab0c0b9df38421e0c13"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del x_train, x_valid, y_train, y_valid, preds_valid\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "21bb50645b1c67d907e42c262d92f975668fccac"
   },
   "outputs": [],
   "source": [
    "x_test = np.array([(np.array(load_img(path_test_images+\"{}.png\".format(idx), grayscale = True))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)\n",
    "\n",
    "preds_test = predict_result(model,x_test,img_size_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7ccac81a492b9caaff4a25401165e145cf2c6f8e"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "pred_dict = {idx: rle_encode(filter_image(preds_test[i] > threshold_best)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}\n",
    "t2 = time.time()\n",
    "\n",
    "print(f\"Usedtime = {t2-t1} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "770d7d596656f4f1ad17a6063ad662ac80e11b24"
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv('submission.csv.gz', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "031bc2ef4548059939fae54c06f24f68e0ad3330"
   },
   "outputs": [],
   "source": [
    "sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds_test2 = filter_image(preds_test > threshold_best)\n",
    "test_df['pred']= None\n",
    "for i, idx in enumerate(tqdm_notebook(test_df.index.values)\n",
    "    test_df.loc[idx, 'pred'] = preds_test2[i]\n",
    "\n",
    "\n",
    "#preds_test[\"img_is_empty\"] = (preds_test.map(np.max) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test.shape, preds_test2.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
